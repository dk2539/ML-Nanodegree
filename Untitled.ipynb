{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'svm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-136-9530c0bca146>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mclf_A\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlinear_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLogisticRegression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mC\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1.0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpenalty\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'l1'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtol\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1e-6\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mclf_B\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msvm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSVC\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mclf_C\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDecisionTreeClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"entropy\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'svm' is not defined"
     ]
    }
   ],
   "source": [
    "clf_A = linear_model.LogisticRegression(C=1.0, penalty='l1', tol=1e-6)\n",
    "\n",
    "clf_B = svm.SVC(random_state=0)\n",
    "\n",
    "clf_C = tree.DecisionTreeClassifier(criterion=\"entropy\",random_state=0)\n",
    "\n",
    "for clf in [clf_A, clf_B, clf_C]:\n",
    "    clf_name = clf.__class__.__name__\n",
    "print clf_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dk2539\\AppData\\Local\\Continuum\\Anaconda2\\lib\\site-packages\\ipykernel\\__main__.py:30: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-83-e830020cc328>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    156\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;36m.2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    157\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 158\u001b[1;33m \u001b[0mdistribution\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    159\u001b[0m \u001b[1;31m#print y\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    160\u001b[0m \u001b[1;31m#print iris.f1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-83-e830020cc328>\u001b[0m in \u001b[0;36mdistribution\u001b[1;34m(data, transformed)\u001b[0m\n\u001b[0;32m     28\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeature\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'capital-gain'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'capital-loss'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m         \u001b[0max\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_subplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m         \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbins\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m25\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'#00A0A0'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m         \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_title\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"'%s' Feature Distribution\"\u001b[0m\u001b[1;33m%\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeature\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfontsize\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m14\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m         \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_xlabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Value\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUEAAAE4CAYAAADFI0E4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSmrNCEpqzQhKas0ISmrt/wCzKm+SOSPYcwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xc8d9dd8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Suppress matplotlib user warnings\n",
    "# Necessary for newer version of matplotlib\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category = UserWarning, module = \"matplotlib\")\n",
    "#\n",
    "# Display inline matplotlib plots with IPython\n",
    "from IPython import get_ipython\n",
    "get_ipython().run_line_magic('matplotlib', 'inline')\n",
    "###########################################\n",
    "\n",
    "import matplotlib.pyplot as pl\n",
    "import matplotlib.patches as mpatches\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from time import time\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "\n",
    "\n",
    "def distribution(data, transformed = False):\n",
    "    \"\"\"\n",
    "    Visualization code for displaying skewed distributions of features\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create figure\n",
    "    fig = pl.figure(figsize = (11,5));\n",
    "\n",
    "    # Skewed feature plotting\n",
    "    for i, feature in enumerate(['capital-gain','capital-loss']):\n",
    "        ax = fig.add_subplot(1, 2, i+1)\n",
    "        ax.hist(data[feature], bins = 25, color = '#00A0A0')\n",
    "        ax.set_title(\"'%s' Feature Distribution\"%(feature), fontsize = 14)\n",
    "        ax.set_xlabel(\"Value\")\n",
    "        ax.set_ylabel(\"Number of Records\")\n",
    "        ax.set_ylim((0, 2000))\n",
    "        ax.set_yticks([0, 500, 1000, 1500, 2000])\n",
    "        ax.set_yticklabels([0, 500, 1000, 1500, \">2000\"])\n",
    "\n",
    "    # Plot aesthetics\n",
    "    if transformed:\n",
    "        fig.suptitle(\"Log-transformed Distributions of Continuous Census Data Features\", \\\n",
    "            fontsize = 16, y = 1.03)\n",
    "    else:\n",
    "        fig.suptitle(\"Skewed Distributions of Continuous Census Data Features\", \\\n",
    "            fontsize = 16, y = 1.03)\n",
    "\n",
    "    fig.tight_layout()\n",
    "    fig.show()\n",
    "\n",
    "\n",
    "def evaluate(results, accuracy, f1):\n",
    "    \"\"\"\n",
    "    Visualization code to display results of various learners.\n",
    "    \n",
    "    inputs:\n",
    "      - learners: a list of supervised learners\n",
    "      - stats: a list of dictionaries of the statistic results from 'train_predict()'\n",
    "      - accuracy: The score for the naive predictor\n",
    "      - f1: The score for the naive predictor\n",
    "    \"\"\"\n",
    "  \n",
    "    # Create figure\n",
    "    fig, ax = pl.subplots(2, 3, figsize = (11,7))\n",
    "\n",
    "    # Constants\n",
    "    bar_width = 0.3\n",
    "    colors = ['#A00000','#00A0A0','#00A000']\n",
    "    \n",
    "    # Super loop to plot four panels of data\n",
    "    for k, learner in enumerate(results.keys()):\n",
    "        for j, metric in enumerate(['train_time', 'acc_train', 'f_train', 'pred_time', 'acc_test', 'f_test']):\n",
    "            for i in np.arange(3):\n",
    "                \n",
    "                # Creative plot code\n",
    "                ax[j/3, j%3].bar(i+k*bar_width, results[learner][i][metric], width = bar_width, color = colors[k])\n",
    "                ax[j/3, j%3].set_xticks([0.45, 1.45, 2.45])\n",
    "                ax[j/3, j%3].set_xticklabels([\"1%\", \"10%\", \"100%\"])\n",
    "                ax[j/3, j%3].set_xlabel(\"Training Set Size\")\n",
    "                ax[j/3, j%3].set_xlim((-0.1, 3.0))\n",
    "    \n",
    "    # Add unique y-labels\n",
    "    ax[0, 0].set_ylabel(\"Time (in seconds)\")\n",
    "    ax[0, 1].set_ylabel(\"Accuracy Score\")\n",
    "    ax[0, 2].set_ylabel(\"F-score\")\n",
    "    ax[1, 0].set_ylabel(\"Time (in seconds)\")\n",
    "    ax[1, 1].set_ylabel(\"Accuracy Score\")\n",
    "    ax[1, 2].set_ylabel(\"F-score\")\n",
    "    \n",
    "    # Add titles\n",
    "    ax[0, 0].set_title(\"Model Training\")\n",
    "    ax[0, 1].set_title(\"Accuracy Score on Training Subset\")\n",
    "    ax[0, 2].set_title(\"F-score on Training Subset\")\n",
    "    ax[1, 0].set_title(\"Model Predicting\")\n",
    "    ax[1, 1].set_title(\"Accuracy Score on Testing Set\")\n",
    "    ax[1, 2].set_title(\"F-score on Testing Set\")\n",
    "    \n",
    "    # Add horizontal lines for naive predictors\n",
    "    ax[0, 1].axhline(y = accuracy, xmin = -0.1, xmax = 3.0, linewidth = 1, color = 'k', linestyle = 'dashed')\n",
    "    ax[1, 1].axhline(y = accuracy, xmin = -0.1, xmax = 3.0, linewidth = 1, color = 'k', linestyle = 'dashed')\n",
    "    ax[0, 2].axhline(y = f1, xmin = -0.1, xmax = 3.0, linewidth = 1, color = 'k', linestyle = 'dashed')\n",
    "    ax[1, 2].axhline(y = f1, xmin = -0.1, xmax = 3.0, linewidth = 1, color = 'k', linestyle = 'dashed')\n",
    "    \n",
    "    # Set y-limits for score panels\n",
    "    ax[0, 1].set_ylim((0, 1))\n",
    "    ax[0, 2].set_ylim((0, 1))\n",
    "    ax[1, 1].set_ylim((0, 1))\n",
    "    ax[1, 2].set_ylim((0, 1))\n",
    "\n",
    "    # Create patches for the legend\n",
    "    patches = []\n",
    "    for i, learner in enumerate(results.keys()):\n",
    "        patches.append(mpatches.Patch(color = colors[i], label = learner))\n",
    "    pl.legend(handles = patches, bbox_to_anchor = (-.80, 2.53), \\\n",
    "               loc = 'upper center', borderaxespad = 0., ncol = 3, fontsize = 'x-large')\n",
    "    \n",
    "    # Aesthetics\n",
    "    pl.suptitle(\"Performance Metrics for Three Supervised Learning Models\", fontsize = 16, y = 1.10)\n",
    "    pl.tight_layout()\n",
    "    pl.show()\n",
    "    \n",
    "\n",
    "def feature_plot(importances, X_train, y_train):\n",
    "    \n",
    "    # Display the five most important features\n",
    "    indices = np.argsort(importances)[::-1]\n",
    "    columns = X_train.columns.values[indices[:5]]\n",
    "    values = importances[indices][:5]\n",
    "\n",
    "    # Creat the plot\n",
    "    fig = pl.figure(figsize = (9,5))\n",
    "    pl.title(\"Normalized Weights for First Five Most Predictive Features\", fontsize = 16)\n",
    "    pl.bar(np.arange(5), values, width = 0.6, align=\"center\", color = '#00A000', \\\n",
    "          label = \"Feature Weight\")\n",
    "    pl.bar(np.arange(5) - 0.3, np.cumsum(values), width = 0.2, align = \"center\", color = '#00A0A0', \\\n",
    "          label = \"Cumulative Feature Weight\")\n",
    "    pl.xticks(np.arange(5), columns)\n",
    "    pl.xlim((-0.5, 4.5))\n",
    "    pl.ylabel(\"Weight\", fontsize = 12)\n",
    "    pl.xlabel(\"Feature\", fontsize = 12)\n",
    "    \n",
    "    pl.legend(loc = 'upper center')\n",
    "    pl.tight_layout()\n",
    "    pl.show()  \n",
    "\n",
    "\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "#import visuals as vs\n",
    "\n",
    "iris =  pd.read_csv(\"e:/Machine_Learning_NanoDegree/projects/CharityML/Data/SAS_data/iris.txt\")\n",
    "\n",
    "y = np.array(iris[['f5']])\n",
    "X = np.array(iris[['f1', 'f2', 'f3', 'f4']])\n",
    "\n",
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size= .2, random_state=0)\n",
    "\n",
    "#distribution(X_train)\n",
    "#print y \n",
    "#print iris.f1\n",
    "#print X[0:10,0:2]\n",
    "\n",
    "gnb = GaussianNB()\n",
    "\n",
    "y_pred = gnb.fit(X_train, y_train).predict(X)\n",
    "\n",
    "clf = GaussianNB()\n",
    "\n",
    "clf.fit(X_train,y_train)\n",
    "pred = clf.predict(X_test)\n",
    "\n",
    "z = pred + y_test\n",
    "\n",
    "#print pred[:120], y[:120]\n",
    "\n",
    "#print(pred[:120],y[:120])\n",
    "\n",
    "#for i in (0,len(z)):\n",
    "#    if pred[i] != y[i]:\n",
    "#        print z[i]\n",
    "\n",
    "print z\n",
    "\n",
    "\n",
    "from sklearn.metrics import accuracy_score \n",
    "print accuracy_score(pred,y_test)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "''' Example Decision Tree'''\n",
    "\n",
    "from sklearn import datasets\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "\n",
    "#print iris\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "#import visuals as vs\n",
    "\n",
    "iris =  pd.read_csv(\"e:/Machine_Learning_NanoDegree/projects/CharityML/Data/SAS_data/iris.txt\")\n",
    "\n",
    "y = np.array(iris[['f5']])\n",
    "X = np.array(iris[['f1', 'f2', 'f3', 'f4']])\n",
    "\n",
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size= .2, random_state=0)\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "\n",
    "clf = DecisionTreeClassifier()\n",
    "\n",
    "y_pred = clf.fit(X_train, y_train).predict(X)\n",
    "\n",
    "clf.fit(X_train,y_train)\n",
    "\n",
    "pred = clf.predict(X_test)\n",
    "\n",
    "z = pred + y_test\n",
    "\n",
    "#print pred[:120], y[:120]\n",
    "\n",
    "#print(pred[:120],y[:120])\n",
    "\n",
    "#for i in (0,len(z)):\n",
    "#    if pred[i] != y[i]:\n",
    "#        print z[i]\n",
    "\n",
    "#print z\n",
    "\n",
    "\n",
    "from sklearn.metrics import accuracy_score \n",
    "print accuracy_score(pred,y_test)  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dk2539\\AppData\\Local\\Continuum\\Anaconda2\\lib\\site-packages\\ipykernel\\__main__.py:29: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    }
   ],
   "source": [
    "''' Example K Nearest Neighbor'''\n",
    "\n",
    "from sklearn import datasets\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "cancer = datasets.load_breast_cancer()\n",
    "\n",
    "\n",
    "#print iris\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "#import visuals as vs\n",
    "\n",
    "iris =  pd.read_csv(\"e:/Machine_Learning_NanoDegree/projects/CharityML/Data/SAS_data/iris.txt\")\n",
    "\n",
    "y = np.array(iris[['f5']])\n",
    "X = np.array(iris[['f1', 'f2', 'f3', 'f4']])\n",
    "\n",
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size= .2, random_state=0)\n",
    "\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "neigh = KNeighborsClassifier(n_neighbors=4)\n",
    "neigh.fit(X_train, y_train) \n",
    "#KNeighborsClassifier(...)\n",
    "\n",
    "pred = clf.predict(X_test)\n",
    "\n",
    "z = pred + y_test\n",
    "\n",
    "#print pred[:120], y[:120]\n",
    "\n",
    "#print(pred[:120],y[:120])\n",
    "\n",
    "#for i in (0,len(z)):\n",
    "#    if pred[i] != y[i]:\n",
    "#        print z[i]\n",
    "\n",
    "#print z\n",
    "\n",
    "\n",
    "from sklearn.metrics import accuracy_score \n",
    "print accuracy_score(pred,y_test)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.566666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dk2539\\AppData\\Local\\Continuum\\Anaconda2\\lib\\site-packages\\sklearn\\utils\\validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "''' Example Stochastic Gradient Descent'''\n",
    "\n",
    "from sklearn import datasets\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "cancer = datasets.load_breast_cancer()\n",
    "\n",
    "\n",
    "#print iris\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "#import visuals as vs\n",
    "\n",
    "iris =  pd.read_csv(\"e:/Machine_Learning_NanoDegree/projects/CharityML/Data/SAS_data/iris.txt\")\n",
    "\n",
    "y = np.array(iris[['f5']])\n",
    "X = np.array(iris[['f1', 'f2', 'f3', 'f4']])\n",
    "\n",
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size= .2, random_state=0)\n",
    "\n",
    "\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "clf = SGDClassifier(loss=\"hinge\", penalty=\"l2\")\n",
    "clf.fit(X_train, y_train) \n",
    "\n",
    "#SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
    "#       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
    "#       learning_rate='optimal', loss='hinge', max_iter=None, n_iter=None,\n",
    "#       n_jobs=1, penalty='l2', power_t=0.5, random_state=None,\n",
    "#       shuffle=True, tol=None, verbose=0, warm_start=False)\n",
    "\n",
    "pred = clf.predict(X_test)\n",
    "\n",
    "z = pred + y_test\n",
    "\n",
    "#print pred[:120], y[:120]\n",
    "\n",
    "#print(pred[:120],y[:120])\n",
    "\n",
    "#for i in (0,len(z)):\n",
    "#    if pred[i] != y[i]:\n",
    "#        print z[i]\n",
    "\n",
    "#print z\n",
    "\n",
    "\n",
    "from sklearn.metrics import accuracy_score \n",
    "print accuracy_score(pred,y_test)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'target_names': array(['malignant', 'benign'], \n",
      "      dtype='|S9'), 'data': array([[  1.79900000e+01,   1.03800000e+01,   1.22800000e+02, ...,\n",
      "          2.65400000e-01,   4.60100000e-01,   1.18900000e-01],\n",
      "       [  2.05700000e+01,   1.77700000e+01,   1.32900000e+02, ...,\n",
      "          1.86000000e-01,   2.75000000e-01,   8.90200000e-02],\n",
      "       [  1.96900000e+01,   2.12500000e+01,   1.30000000e+02, ...,\n",
      "          2.43000000e-01,   3.61300000e-01,   8.75800000e-02],\n",
      "       ..., \n",
      "       [  1.66000000e+01,   2.80800000e+01,   1.08300000e+02, ...,\n",
      "          1.41800000e-01,   2.21800000e-01,   7.82000000e-02],\n",
      "       [  2.06000000e+01,   2.93300000e+01,   1.40100000e+02, ...,\n",
      "          2.65000000e-01,   4.08700000e-01,   1.24000000e-01],\n",
      "       [  7.76000000e+00,   2.45400000e+01,   4.79200000e+01, ...,\n",
      "          0.00000000e+00,   2.87100000e-01,   7.03900000e-02]]), 'target': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1,\n",
      "       1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0,\n",
      "       1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1,\n",
      "       0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
      "       0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1,\n",
      "       0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1,\n",
      "       0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0,\n",
      "       0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1,\n",
      "       1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1,\n",
      "       1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0,\n",
      "       1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1,\n",
      "       1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1,\n",
      "       0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1,\n",
      "       1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1,\n",
      "       0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1,\n",
      "       1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1,\n",
      "       1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1,\n",
      "       1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1]), 'DESCR': 'Breast Cancer Wisconsin (Diagnostic) Database\\n\\nNotes\\n-----\\nData Set Characteristics:\\n    :Number of Instances: 569\\n\\n    :Number of Attributes: 30 numeric, predictive attributes and the class\\n\\n    :Attribute Information:\\n        - radius (mean of distances from center to points on the perimeter)\\n        - texture (standard deviation of gray-scale values)\\n        - perimeter\\n        - area\\n        - smoothness (local variation in radius lengths)\\n        - compactness (perimeter^2 / area - 1.0)\\n        - concavity (severity of concave portions of the contour)\\n        - concave points (number of concave portions of the contour)\\n        - symmetry \\n        - fractal dimension (\"coastline approximation\" - 1)\\n        \\n        The mean, standard error, and \"worst\" or largest (mean of the three\\n        largest values) of these features were computed for each image,\\n        resulting in 30 features.  For instance, field 3 is Mean Radius, field\\n        13 is Radius SE, field 23 is Worst Radius.\\n        \\n        - class:\\n                - WDBC-Malignant\\n                - WDBC-Benign\\n\\n    :Summary Statistics:\\n\\n    ===================================== ======= ========\\n                                           Min     Max\\n    ===================================== ======= ========\\n    radius (mean):                         6.981   28.11\\n    texture (mean):                        9.71    39.28\\n    perimeter (mean):                      43.79   188.5\\n    area (mean):                           143.5   2501.0\\n    smoothness (mean):                     0.053   0.163\\n    compactness (mean):                    0.019   0.345\\n    concavity (mean):                      0.0     0.427\\n    concave points (mean):                 0.0     0.201\\n    symmetry (mean):                       0.106   0.304\\n    fractal dimension (mean):              0.05    0.097\\n    radius (standard error):               0.112   2.873\\n    texture (standard error):              0.36    4.885\\n    perimeter (standard error):            0.757   21.98\\n    area (standard error):                 6.802   542.2\\n    smoothness (standard error):           0.002   0.031\\n    compactness (standard error):          0.002   0.135\\n    concavity (standard error):            0.0     0.396\\n    concave points (standard error):       0.0     0.053\\n    symmetry (standard error):             0.008   0.079\\n    fractal dimension (standard error):    0.001   0.03\\n    radius (worst):                        7.93    36.04\\n    texture (worst):                       12.02   49.54\\n    perimeter (worst):                     50.41   251.2\\n    area (worst):                          185.2   4254.0\\n    smoothness (worst):                    0.071   0.223\\n    compactness (worst):                   0.027   1.058\\n    concavity (worst):                     0.0     1.252\\n    concave points (worst):                0.0     0.291\\n    symmetry (worst):                      0.156   0.664\\n    fractal dimension (worst):             0.055   0.208\\n    ===================================== ======= ========\\n\\n    :Missing Attribute Values: None\\n\\n    :Class Distribution: 212 - Malignant, 357 - Benign\\n\\n    :Creator:  Dr. William H. Wolberg, W. Nick Street, Olvi L. Mangasarian\\n\\n    :Donor: Nick Street\\n\\n    :Date: November, 1995\\n\\nThis is a copy of UCI ML Breast Cancer Wisconsin (Diagnostic) datasets.\\nhttps://goo.gl/U2Uwz2\\n\\nFeatures are computed from a digitized image of a fine needle\\naspirate (FNA) of a breast mass.  They describe\\ncharacteristics of the cell nuclei present in the image.\\nA few of the images can be found at\\nhttp://www.cs.wisc.edu/~street/images/\\n\\nSeparating plane described above was obtained using\\nMultisurface Method-Tree (MSM-T) [K. P. Bennett, \"Decision Tree\\nConstruction Via Linear Programming.\" Proceedings of the 4th\\nMidwest Artificial Intelligence and Cognitive Science Society,\\npp. 97-101, 1992], a classification method which uses linear\\nprogramming to construct a decision tree.  Relevant features\\nwere selected using an exhaustive search in the space of 1-4\\nfeatures and 1-3 separating planes.\\n\\nThe actual linear program used to obtain the separating plane\\nin the 3-dimensional space is that described in:\\n[K. P. Bennett and O. L. Mangasarian: \"Robust Linear\\nProgramming Discrimination of Two Linearly Inseparable Sets\",\\nOptimization Methods and Software 1, 1992, 23-34].\\n\\nThis database is also available through the UW CS ftp server:\\n\\nftp ftp.cs.wisc.edu\\ncd math-prog/cpo-dataset/machine-learn/WDBC/\\n\\nReferences\\n----------\\n   - W.N. Street, W.H. Wolberg and O.L. Mangasarian. Nuclear feature extraction \\n     for breast tumor diagnosis. IS&T/SPIE 1993 International Symposium on \\n     Electronic Imaging: Science and Technology, volume 1905, pages 861-870, \\n     San Jose, CA, 1993. \\n   - O.L. Mangasarian, W.N. Street and W.H. Wolberg. Breast cancer diagnosis and \\n     prognosis via linear programming. Operations Research, 43(4), pages 570-577, \\n     July-August 1995.\\n   - W.H. Wolberg, W.N. Street, and O.L. Mangasarian. Machine learning techniques\\n     to diagnose breast cancer from fine-needle aspirates. Cancer Letters 77 (1994) \\n     163-171.\\n', 'feature_names': array(['mean radius', 'mean texture', 'mean perimeter', 'mean area',\n",
      "       'mean smoothness', 'mean compactness', 'mean concavity',\n",
      "       'mean concave points', 'mean symmetry', 'mean fractal dimension',\n",
      "       'radius error', 'texture error', 'perimeter error', 'area error',\n",
      "       'smoothness error', 'compactness error', 'concavity error',\n",
      "       'concave points error', 'symmetry error', 'fractal dimension error',\n",
      "       'worst radius', 'worst texture', 'worst perimeter', 'worst area',\n",
      "       'worst smoothness', 'worst compactness', 'worst concavity',\n",
      "       'worst concave points', 'worst symmetry', 'worst fractal dimension'], \n",
      "      dtype='|S23')}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn import datasets\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "cancer = datasets.load_breast_cancer()\n",
    "\n",
    "\n",
    "print cancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.748251748252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dk2539\\AppData\\Local\\Continuum\\Anaconda2\\lib\\site-packages\\sklearn\\svm\\base.py:514: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y_ = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "''' Example Support Vector Machine'''\n",
    "\n",
    "from sklearn import datasets\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "cancer = datasets.load_breast_cancer()\n",
    "\n",
    "\n",
    "#print iris\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "#import visuals as vs\n",
    "\n",
    "iris =  pd.read_csv(\"e:/Machine_Learning_NanoDegree/projects/CharityML/Data/SAS_data/iris.txt\")\n",
    "\n",
    "y = np.array(iris[['f5']])\n",
    "X = np.array(iris[['f1', 'f2', 'f3', 'f4']])\n",
    "\n",
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size= .95, random_state=0)\n",
    "\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "clf = SVC()\n",
    "clf.fit(X_train, y_train) \n",
    "\n",
    "#SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
    "#    decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
    "#    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
    "#    tol=0.001, verbose=False)\n",
    "\n",
    "pred = clf.predict(X_test)\n",
    "\n",
    "z = pred + y_test\n",
    "\n",
    "#print pred[:120], y[:120]\n",
    "\n",
    "#print(pred[:120],y[:120])\n",
    "\n",
    "#for i in (0,len(z)):\n",
    "#    if pred[i] != y[i]:\n",
    "#        print z[i]\n",
    "\n",
    "#print z\n",
    "\n",
    "\n",
    "from sklearn.metrics import accuracy_score \n",
    "print accuracy_score(pred,y_test)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.748251748252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dk2539\\AppData\\Local\\Continuum\\Anaconda2\\lib\\site-packages\\sklearn\\svm\\base.py:514: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y_ = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "''' Example Support Vector Machine'''\n",
    "\n",
    "from sklearn import datasets\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "cancer = datasets.load_breast_cancer()\n",
    "\n",
    "\n",
    "#print iris\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "#import visuals as vs\n",
    "\n",
    "iris =  pd.read_csv(\"e:/Machine_Learning_NanoDegree/projects/CharityML/Data/SAS_data/iris.txt\")\n",
    "\n",
    "y = np.array(iris[['f5']])\n",
    "X = np.array(iris[['f1', 'f2', 'f3', 'f4']])\n",
    "\n",
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size= .95, random_state=0)\n",
    "\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "clf = SVC()\n",
    "clf.fit(X_train, y_train) \n",
    "\n",
    "#SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
    "#    decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
    "#    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
    "#    tol=0.001, verbose=False)\n",
    "\n",
    "pred = clf.predict(X_test)\n",
    "\n",
    "z = pred + y_test\n",
    "\n",
    "#print pred[:120], y[:120]\n",
    "\n",
    "#print(pred[:120],y[:120])\n",
    "\n",
    "#for i in (0,len(z)):\n",
    "#    if pred[i] != y[i]:\n",
    "#        print z[i]\n",
    "\n",
    "#print z\n",
    "\n",
    "\n",
    "from sklearn.metrics import accuracy_score \n",
    "print accuracy_score(pred,y_test)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPwAAADECAYAAAC7gkynAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRMAHQRkRAR8EZcR3Cs2Wu7FXWqMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xcdf0518>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.748251748252\n"
     ]
    }
   ],
   "source": [
    "'''Logistic Regression Classifier'''\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import linear_model, datasets\n",
    "\n",
    "# import some data to play with\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data[:, :2]  # we only take the first two features.\n",
    "Y = iris.target\n",
    "\n",
    "h = .3  # step size in the mesh\n",
    "\n",
    "logreg = linear_model.LogisticRegression(C=1e5)\n",
    "\n",
    "# we create an instance of Neighbours Classifier and fit the data.\n",
    "logreg.fit(X, Y)\n",
    "\n",
    "# Plot the decision boundary. For that, we will assign a color to each\n",
    "# point in the mesh [x_min, x_max]x[y_min, y_max].\n",
    "x_min, x_max = X[:, 0].min() - .5, X[:, 0].max() + .5\n",
    "y_min, y_max = X[:, 1].min() - .5, X[:, 1].max() + .5\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "Z = logreg.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "\n",
    "# Put the result into a color plot\n",
    "Z = Z.reshape(xx.shape)\n",
    "plt.figure(1, figsize=(4, 3))\n",
    "plt.pcolormesh(xx, yy, Z, cmap=plt.cm.Paired)\n",
    "\n",
    "# Plot also the training points\n",
    "plt.scatter(X[:, 0], X[:, 1], c=Y, edgecolors='k', cmap=plt.cm.Paired)\n",
    "plt.xlabel('Sepal length')\n",
    "plt.ylabel('Sepal width')\n",
    "\n",
    "plt.xlim(xx.min(), xx.max())\n",
    "plt.ylim(yy.min(), yy.max())\n",
    "plt.xticks(())\n",
    "plt.yticks(())\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "from sklearn.metrics import accuracy_score \n",
    "print accuracy_score(pred,y_test)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.977777777778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dk2539\\AppData\\Local\\Continuum\\Anaconda2\\lib\\site-packages\\sklearn\\utils\\validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "''' Example Bagging'''\n",
    "\n",
    "from sklearn import datasets\n",
    "iris1 = datasets.load_iris()\n",
    "\n",
    "cancer = datasets.load_breast_cancer()\n",
    "\n",
    "\n",
    "#print iris\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "#import visuals as vs\n",
    "\n",
    "iris =  pd.read_csv(\"e:/Machine_Learning_NanoDegree/projects/CharityML/Data/SAS_data/iris.txt\")\n",
    "\n",
    "y = np.array(iris[['f5']])\n",
    "X = np.array(iris[['f1', 'f2', 'f3', 'f4']])\n",
    "\n",
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size= .3, random_state=0)\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "#from imblearn.ensemble import BalancedBaggingClassifier \n",
    "#from imblearn.ensemble import EasyEnsemble\n",
    "from sklearn.ensemble import BaggingClassifier, BaggingRegressor\n",
    "\n",
    "#ee = EasyEnsemble(random_state=0, n_subsets=10)\n",
    "#bbc = BalancedBaggingClassifier(random_state=42)\n",
    "ee  = BaggingClassifier()\n",
    "\n",
    "ee.fit(X_train, y_train) \n",
    "\n",
    "\n",
    "#SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
    "#    decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
    "#    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
    "#    tol=0.001, verbose=False)\n",
    "\n",
    "pred = ee.predict(X_test)\n",
    "\n",
    "z = pred + y_test\n",
    "\n",
    "#print pred[:120], y[:120]\n",
    "\n",
    "#print(pred[:120],y[:120])\n",
    "\n",
    "#for i in (0,len(z)):\n",
    "#    if pred[i] != y[i]:\n",
    "#        print z[i]\n",
    "\n",
    "#print z\n",
    "\n",
    "\n",
    "from sklearn.metrics import accuracy_score \n",
    "print accuracy_score(pred,y_test)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.911111111111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dk2539\\AppData\\Local\\Continuum\\Anaconda2\\lib\\site-packages\\sklearn\\utils\\validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "''' Example AdaBoosting'''\n",
    "\n",
    "from sklearn import datasets\n",
    "iris1 = datasets.load_iris()\n",
    "\n",
    "cancer = datasets.load_breast_cancer()\n",
    "\n",
    "\n",
    "#print iris\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "#import visuals as vs\n",
    "\n",
    "iris =  pd.read_csv(\"e:/Machine_Learning_NanoDegree/projects/CharityML/Data/SAS_data/iris.txt\")\n",
    "\n",
    "y = np.array(iris[['f5']])\n",
    "X = np.array(iris[['f1', 'f2', 'f3', 'f4']])\n",
    "\n",
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size= .3, random_state=0)\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "#from imblearn.ensemble import BalancedBaggingClassifier \n",
    "#from imblearn.ensemble import EasyEnsemble\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "#ee = EasyEnsemble(random_state=0, n_subsets=10)\n",
    "#bbc = BalancedBaggingClassifier(random_state=42)\n",
    "ee  = AdaBoostClassifier()\n",
    "\n",
    "ee.fit(X_train, y_train) \n",
    "\n",
    "\n",
    "#SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
    "#    decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
    "#    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
    "#    tol=0.001, verbose=False)\n",
    "\n",
    "pred = ee.predict(X_test)\n",
    "\n",
    "z = pred + y_test\n",
    "\n",
    "#print pred[:120], y[:120]\n",
    "\n",
    "#print(pred[:120],y[:120])\n",
    "\n",
    "#for i in (0,len(z)):\n",
    "#    if pred[i] != y[i]:\n",
    "#        print z[i]\n",
    "\n",
    "#print z\n",
    "\n",
    "\n",
    "from sklearn.metrics import accuracy_score \n",
    "print accuracy_score(pred,y_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.933333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dk2539\\AppData\\Local\\Continuum\\Anaconda2\\lib\\site-packages\\sklearn\\utils\\validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of mislabeled points out of a total 150 points : 6\n"
     ]
    }
   ],
   "source": [
    ">>> from sklearn import datasets\n",
    ">>> iris = datasets.load_iris()\n",
    ">>> from sklearn.naive_bayes import GaussianNB\n",
    ">>> gnb = GaussianNB()\n",
    ">>> y_pred = gnb.fit(iris.data, iris.target).predict(iris.data)\n",
    ">>> print(\"Number of mislabeled points out of a total %d points : %d\"\n",
    "...       % (iris.data.shape[0],(iris.target != y_pred).sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
